#
# elDoc AI Podman (Docker) Compose environment file
# Make sure to place the .env file in the same directory as compose.yaml.
#

# Host name where users access elDoc
ELDOC_HOST=eldoc.domain.com

# ************************************************************
# Common configuration parameters relevant for all models: chat, agent, embed, rerank, vl
#
# ELDOC_AI_*_PROVIDER        - Model provider. Supported values: 'openai', 'bedrock', 'onnx'
#                              (ONNX is supported only for Embed and Rerank models)
# ELDOC_AI_*_SECRET          - Provider API key or secret
# ELDOC_AI_*_MODEL_ID        - Provider model ID
# ELDOC_AI_*_TIMEOUT_SEC     - Provider endpoint request timeout in seconds. Defaults to 60 seconds if not set.
# ELDOC_AI_*_BEDROCK_REGION  - AWS Bedrock region
# ELDOC_AI_*_BEDROCK_KEY_ID  - AWS Bedrock Access Key ID (Access Key Secret must be provided via *_SECRET param)
# ELDOC_AI_*_OPENAI_ENDPOINT - OpenAI-compatible API endpoint URL.
#                              Defaults to the official OpenAI endpoint:
#                              https://api.openai.com/v1
#
# Common configuration parameters relevant for models: chat, agent, vl
# ELDOC_AI_*_MAX_TOKENS_OUT  - Maximum number of tokens generated per model call. Default: not set (uses provider's defaults).
#                              Recommended: set the maximum value supported by the selected model.
#

# ************************************************************
# AI & LLM Model Configuration – Chat (sample values)
ELDOC_AI_CHAT_PROVIDER=bedrock
ELDOC_AI_CHAT_SECRET=YYYYYYYYYYYYYYY
ELDOC_AI_CHAT_MODEL_ID=us.deepseek.r1-v1:0
ELDOC_AI_CHAT_TIMEOUT_SEC=
ELDOC_AI_CHAT_MAX_TOKENS_OUT=10000
ELDOC_AI_CHAT_BEDROCK_REGION=us-east-2
ELDOC_AI_CHAT_BEDROCK_KEY_ID=XXXXXXXXXXXXXXX
ELDOC_AI_CHAT_OPENAI_ENDPOINT=

# AI & LLM Model Configuration – Agent (sample values)
ELDOC_AI_AGENT_PROVIDER=bedrock
ELDOC_AI_AGENT_SECRET=YYYYYYYYYYYYYYY
ELDOC_AI_AGENT_MODEL_ID=eu.amazon.nova-pro-v1:0
ELDOC_AI_AGENT_TIMEOUT_SEC=
ELDOC_AI_AGENT_MAX_TOKENS_OUT=10000
ELDOC_AI_AGENT_BEDROCK_REGION=eu-central-1
ELDOC_AI_AGENT_BEDROCK_KEY_ID=XXXXXXXXXXXXXXX
ELDOC_AI_AGENT_OPENAI_ENDPOINT=

# AI & LLM Model Configuration – Vision-Language (VL) Model (sample values)
ELDOC_AI_VL_PROVIDER=openai
ELDOC_AI_VL_SECRET=sk-1234
ELDOC_AI_VL_MODEL_ID=Qwen3-VL-30B-A3B-Instruct
ELDOC_AI_VL_TIMEOUT_SEC=
ELDOC_AI_VL_MAX_TOKENS_OUT=65536
ELDOC_AI_VL_BEDROCK_REGION=
ELDOC_AI_VL_BEDROCK_KEY_ID=
ELDOC_AI_VL_OPENAI_ENDPOINT=http://llm.domain.com:8014/v1

# AI & LLM Model Configuration – Embeddings
# IMPORTANT: Embedding model settings must match the configuration defined in JMC-config.
# ELDOC_AI_EMBED_MODEL_PATH - Path to the directory containing model files (for 'onnx' provider): model.onnx, tokenizer.json
# ELDOC_AI_EMBED_MODEL_DIMS - Embedding vector dimensions (from model documentation). If omitted, the system attempts to auto-detect.
ELDOC_AI_EMBED_PROVIDER=onnx
ELDOC_AI_EMBED_SECRET=
ELDOC_AI_EMBED_MODEL_ID=
# Note: The elDoc AIO container includes an ONNX embedding model available at the default path below.
ELDOC_AI_EMBED_MODEL_PATH=/local/llm/bge-m3-int8
ELDOC_AI_EMBED_MODEL_DIMS=1024
ELDOC_AI_EMBED_TIMEOUT_SEC=
ELDOC_AI_EMBED_BEDROCK_REGION=
ELDOC_AI_EMBED_BEDROCK_KEY_ID=
ELDOC_AI_EMBED_OPENAI_ENDPOINT=

# AI & LLM Model Configuration – Reranking
# ELDOC_AI_RERANK_MODEL_PATH - Path to the directory containing model files (for 'onnx' provider):
#                              model.onnx, tokenizer.json, tokenizer_config.json
ELDOC_AI_RERANK_PROVIDER=onnx
ELDOC_AI_RERANK_SECRET=
ELDOC_AI_RERANK_MODEL_ID=
ELDOC_AI_RERANK_TIMEOUT_SEC=
# Note: The elDoc AIO container includes an ONNX reranking model available at the default path below.
ELDOC_AI_RERANK_MODEL_PATH=/local/llm/bge-reranker-v2-m3-int8
ELDOC_AI_RERANK_BEDROCK_REGION=
ELDOC_AI_RERANK_BEDROCK_KEY_ID=
ELDOC_AI_RERANK_OPENAI_ENDPOINT=
# ************************************************************
